{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "03) CNN - Convolutional Neural Network - MNIST (GPU)",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yceffort/pytorch-study/blob/master/03)_CNN_Convolutional_Neural_Network_MNIST_(GPU).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "LF2HPy4gXUGV",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch.autograd import Variable\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "\n",
        "from sklearn.datasets import load_digits\n",
        "from sklearn import datasets, model_selection\n",
        "\n",
        "from matplotlib import pyplot as plt\n",
        "from matplotlib import cm\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "%matplotlib inline"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "WeOx6NuBXes6",
        "colab_type": "code",
        "outputId": "0da11267-ed3b-4023-bdd6-84841a17a3b0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "import urllib\n",
        "\n",
        "from scipy.io import loadmat\n",
        "mnist_alternative_url = \"https://github.com/amplab/datascience-sp14/raw/master/lab7/mldata/mnist-original.mat\"\n",
        "mnist_path = \"./mnist-original.mat\"\n",
        "response = urllib.request.urlopen(mnist_alternative_url)\n",
        "with open(mnist_path, \"wb\") as f:\n",
        "    content = response.read()\n",
        "    f.write(content)\n",
        "mnist_raw = loadmat(mnist_path)\n",
        "mnist = {\n",
        "    \"data\": mnist_raw[\"data\"].T,\n",
        "    \"target\": mnist_raw[\"label\"][0],\n",
        "    \"COL_NAMES\": [\"label\", \"data\"],\n",
        "    \"DESCR\": \"mldata.org dataset: mnist-original\",\n",
        "}\n",
        "print(\"Success!\")"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Success!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "NsVu-CmRXjG0",
        "colab_type": "code",
        "outputId": "104cc569-fdb1-455e-f4d1-fb1ac66458d0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 233
        }
      },
      "cell_type": "code",
      "source": [
        "mnist_data = mnist['data'] / 255\n",
        "\n",
        "pd.DataFrame(mnist_data).head()"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>...</th>\n",
              "      <th>774</th>\n",
              "      <th>775</th>\n",
              "      <th>776</th>\n",
              "      <th>777</th>\n",
              "      <th>778</th>\n",
              "      <th>779</th>\n",
              "      <th>780</th>\n",
              "      <th>781</th>\n",
              "      <th>782</th>\n",
              "      <th>783</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 784 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "   0    1    2    3    4    5    6    7    8    9   ...   774  775  776  777  \\\n",
              "0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0 ...   0.0  0.0  0.0  0.0   \n",
              "1  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0 ...   0.0  0.0  0.0  0.0   \n",
              "2  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0 ...   0.0  0.0  0.0  0.0   \n",
              "3  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0 ...   0.0  0.0  0.0  0.0   \n",
              "4  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0 ...   0.0  0.0  0.0  0.0   \n",
              "\n",
              "   778  779  780  781  782  783  \n",
              "0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
              "1  0.0  0.0  0.0  0.0  0.0  0.0  \n",
              "2  0.0  0.0  0.0  0.0  0.0  0.0  \n",
              "3  0.0  0.0  0.0  0.0  0.0  0.0  \n",
              "4  0.0  0.0  0.0  0.0  0.0  0.0  \n",
              "\n",
              "[5 rows x 784 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "metadata": {
        "id": "2lbC7L_FXs8L",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "mnist_label = mnist['target']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Y2f6ARQYXwXQ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "train_size = 50000\n",
        "test_size = 500\n",
        "train_X, test_X, train_Y, test_Y = model_selection.train_test_split(mnist_data, \n",
        "                                                                    mnist_label, \n",
        "                                                                    train_size=train_size, \n",
        "                                                                    test_size=test_size\n",
        "                                                                   )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Zz24T2oZoWF-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "0c54c0d9-86f2-492d-9ad3-011bbca7cdb9"
      },
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "device"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda', index=0)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "metadata": {
        "id": "rB3maSo3XyXf",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# 1차원 배열을 28 * 28 이차원 배열로 만듬\n",
        "train_X = train_X.reshape((len(train_X), 1, 28, 28))\n",
        "test_X = test_X.reshape((len(test_X), 1, 28, 28))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "emnemk66e8H8",
        "colab_type": "code",
        "outputId": "3af8dd6c-fb78-4316-b063-c5c394a7076a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "cell_type": "code",
      "source": [
        "train_X = torch.from_numpy(train_X).float().to(device)\n",
        "train_Y = torch.from_numpy(train_Y).long().to(device)\n",
        "\n",
        "\n",
        "test_X = torch.from_numpy(test_X).float().to(device)\n",
        "test_Y = torch.from_numpy(test_Y).long().to(device)\n",
        "\n",
        "print(train_X.shape)\n",
        "print(train_Y.shape)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([50000, 1, 28, 28])\n",
            "torch.Size([50000])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "t712xNCngApe",
        "colab_type": "code",
        "outputId": "2c123205-49fd-4381-b404-85d7e13de0dd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1921
        }
      },
      "cell_type": "code",
      "source": [
        "# 설명변수와 목적변수 텐서를 합침\n",
        "train = TensorDataset(train_X, train_Y)\n",
        "\n",
        "# 텐서의 첫 번째 데이터를 확인\n",
        "print(train[0])\n",
        "\n",
        "# 미니배치 분할\n",
        "train_loader = DataLoader(train, batch_size=100, shuffle=True)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000],\n",
            "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000],\n",
            "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000],\n",
            "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000],\n",
            "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000],\n",
            "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.2039, 0.5020,\n",
            "          0.8314, 0.9882, 0.2118, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000],\n",
            "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0118, 0.2392, 0.7059, 0.9725, 0.9961,\n",
            "          0.9961, 0.9961, 0.5216, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000],\n",
            "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0784, 0.5490, 0.9961, 0.9961, 0.8431, 0.5216,\n",
            "          0.6667, 0.9961, 0.7137, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000],\n",
            "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.2941, 0.8314, 0.9961, 0.8392, 0.4157, 0.0824, 0.0000,\n",
            "          0.5490, 0.9961, 0.9922, 0.9255, 0.1373, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000],\n",
            "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.5804, 0.9569, 0.9765, 0.7020, 0.0471, 0.0000, 0.0000, 0.0314,\n",
            "          0.8784, 0.9961, 0.9961, 0.8902, 0.1216, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000],\n",
            "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.1647,\n",
            "          0.9569, 0.9961, 0.3922, 0.0000, 0.0000, 0.0000, 0.0000, 0.5725,\n",
            "          0.9961, 0.9843, 0.5490, 0.1333, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000],\n",
            "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0941,\n",
            "          0.8314, 0.9961, 0.7412, 0.5569, 0.2118, 0.1725, 0.3569, 0.9882,\n",
            "          0.9608, 0.3333, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000],\n",
            "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.2588, 0.6745, 0.9373, 0.9961, 0.9961, 0.9647, 0.9686, 0.9961,\n",
            "          0.5137, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000],\n",
            "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0627, 0.3294, 0.7804, 0.9961, 0.9961, 0.9961,\n",
            "          0.6275, 0.1882, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000],\n",
            "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000, 0.0784, 0.9569, 0.8431, 0.9373,\n",
            "          0.9961, 0.8039, 0.0667, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000],\n",
            "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.1686, 0.4902, 0.8941, 0.1059, 0.1294,\n",
            "          0.9176, 0.9961, 0.3608, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000],\n",
            "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0667, 0.7098, 0.7882, 0.1765, 0.0000, 0.0000,\n",
            "          0.5490, 0.9961, 0.7137, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000],\n",
            "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.2118, 0.9961, 0.9961, 0.0549, 0.0000, 0.0000,\n",
            "          0.5490, 0.9961, 0.7137, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000],\n",
            "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.2118, 0.9961, 0.8627, 0.0314, 0.0000, 0.0000,\n",
            "          0.5490, 0.9961, 0.7137, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000],\n",
            "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.2118, 0.9961, 0.7686, 0.0157, 0.0000, 0.0000,\n",
            "          0.5490, 0.9961, 0.7137, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000],\n",
            "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.2118, 0.9961, 0.9961, 0.0549, 0.0000, 0.0000,\n",
            "          0.6039, 0.9961, 0.5137, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000],\n",
            "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0471, 0.8627, 0.9961, 0.0627, 0.0000, 0.0078,\n",
            "          0.9255, 0.9765, 0.2039, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000],\n",
            "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.4549, 0.9961, 0.7255, 0.0667, 0.6275,\n",
            "          0.9961, 0.5804, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000],\n",
            "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.1098, 0.9569, 0.9961, 0.9137, 0.9961,\n",
            "          0.9961, 0.3922, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000],\n",
            "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000, 0.4392, 0.9765, 0.9961, 0.9961,\n",
            "          0.7255, 0.0510, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000],\n",
            "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000],\n",
            "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000],\n",
            "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000]]], device='cuda:0'), tensor(8, device='cuda:0'))\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "6CdY5xVrZKVr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "outputId": "f177f0e3-1b48-4018-cc91-63c16f167af9"
      },
      "cell_type": "code",
      "source": [
        "class Net(nn.Module):\n",
        "  \n",
        "  def __init__(self):\n",
        "    \n",
        "    super(Net, self).__init__()\n",
        "\n",
        "    # 합성곱층\n",
        "    # 입력채널 수(1), 출력채널수(6), 필터크기(5)\n",
        "    self.conv1 = nn.Conv2d(1, 6, 5)\n",
        "    self.conv2 = nn.Conv2d(6, 16, 5)\n",
        "    \n",
        "    # 전결합층\n",
        "    self.fc1 = nn.Linear(256, 64)\n",
        "    self.fc2 = nn.Linear(64, 10)\n",
        "    \n",
        "  def forward(self, x):\n",
        "    \n",
        "    # 풀링층\n",
        "    \n",
        "    x = F.max_pool2d(F.relu(self.conv1(x)), 2)\n",
        "    x = F.max_pool2d(F.relu(self.conv2(x)), 2)\n",
        "    \n",
        "    x = x.view(-1, 256)\n",
        "    x = F.relu(self.fc1(x))\n",
        "    x = self.fc2(x)\n",
        "    \n",
        "    return F.log_softmax(x)\n",
        "  \n",
        "  \n",
        "model = Net()\n",
        "model.cuda()"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Net(\n",
              "  (conv1): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1))\n",
              "  (conv2): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))\n",
              "  (fc1): Linear(in_features=256, out_features=64, bias=True)\n",
              "  (fc2): Linear(in_features=64, out_features=10, bias=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "metadata": {
        "id": "c_8dM07nZPCu",
        "colab_type": "code",
        "outputId": "507202e0-e5b3-4e1a-893c-8dd30fef0b9a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1754
        }
      },
      "cell_type": "code",
      "source": [
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.01)\n",
        "\n",
        "for epoch in range(1000):\n",
        "  total_loss = 0\n",
        "  \n",
        "  for train_x, train_y in train_loader:\n",
        "    train_x, train_y = Variable(train_x), Variable(train_y)\n",
        "    optimizer.zero_grad()\n",
        "    output = model(train_x)\n",
        "    loss = criterion(output, train_y)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    total_loss += loss.data.item()\n",
        "    \n",
        "  if (epoch+1) % 10 == 0:\n",
        "    print(epoch+1, total_loss)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:27: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "10 0.030671952446329698\n",
            "20 0.03015235775859537\n",
            "30 0.029745956552838848\n",
            "40 0.0292611620693215\n",
            "50 0.028835502050768014\n",
            "60 0.02839404038103055\n",
            "70 0.028079484135432153\n",
            "80 0.027570092388842227\n",
            "90 0.027263242718007064\n",
            "100 0.02684085885141574\n",
            "110 0.02642699931359971\n",
            "120 0.026130192723707424\n",
            "130 0.025821948468831124\n",
            "140 0.02543859127056436\n",
            "150 0.02509891732199776\n",
            "160 0.024828102834021593\n",
            "170 0.024586088391785665\n",
            "180 0.024220867548180536\n",
            "190 0.023932625614460967\n",
            "200 0.02349982105174675\n",
            "210 0.02323520285423797\n",
            "220 0.022970407496146095\n",
            "230 0.022727029930294407\n",
            "240 0.022403059434871864\n",
            "250 0.02218858177850791\n",
            "260 0.021978349164399447\n",
            "270 0.021647632841578\n",
            "280 0.021329593536982827\n",
            "290 0.021157773268718927\n",
            "300 0.02088634742253248\n",
            "310 0.020668513378197417\n",
            "320 0.020457265496432342\n",
            "330 0.020187116923498394\n",
            "340 0.020008971288632438\n",
            "350 0.019764990657677117\n",
            "360 0.019564651778438247\n",
            "370 0.019388761833322832\n",
            "380 0.019160813524228715\n",
            "390 0.018959232884650845\n",
            "400 0.01869796635010701\n",
            "410 0.018609466016634713\n",
            "420 0.018327736059130517\n",
            "430 0.018229623653226668\n",
            "440 0.018010826736944097\n",
            "450 0.017812152845515072\n",
            "460 0.01762906289334154\n",
            "470 0.017449246365913496\n",
            "480 0.017306354486500197\n",
            "490 0.017095224866395142\n",
            "500 0.016956868999081554\n",
            "510 0.016817862964909835\n",
            "520 0.016673053058596565\n",
            "530 0.01647727462148474\n",
            "540 0.016244247465003525\n",
            "550 0.01618053656897578\n",
            "560 0.016040200580370367\n",
            "570 0.015868469555955222\n",
            "580 0.015760639043543634\n",
            "590 0.015625940515199943\n",
            "600 0.015464793683854339\n",
            "610 0.015345709447913247\n",
            "620 0.015201202512203693\n",
            "630 0.015046419240398734\n",
            "640 0.014932276942886347\n",
            "650 0.014781997206732456\n",
            "660 0.014645071974335622\n",
            "670 0.014533600230203447\n",
            "680 0.014443910212243338\n",
            "690 0.014312161882653385\n",
            "700 0.01418967697663831\n",
            "710 0.014061365293041916\n",
            "720 0.013937472721732291\n",
            "730 0.01381598231166592\n",
            "740 0.013734020732208307\n",
            "750 0.013617918024735332\n",
            "760 0.013509923833847637\n",
            "770 0.013401352806719835\n",
            "780 0.013255886738775757\n",
            "790 0.013185710325672062\n",
            "800 0.01308214548548392\n",
            "810 0.013002763144180252\n",
            "820 0.012881923406848017\n",
            "830 0.012768728649519723\n",
            "840 0.012689672577238298\n",
            "850 0.012589247911644064\n",
            "860 0.012505966602979868\n",
            "870 0.012403663555263122\n",
            "880 0.012304879992594664\n",
            "890 0.012206960130262345\n",
            "900 0.012139936872063828\n",
            "910 0.012040199624353765\n",
            "920 0.01197828291768488\n",
            "930 0.011868175449315288\n",
            "940 0.011800621562308322\n",
            "950 0.011691308192487426\n",
            "960 0.01160252873993528\n",
            "970 0.011539503385319172\n",
            "980 0.011454801844092088\n",
            "990 0.011393822855801261\n",
            "1000 0.011282447179065125\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "00NObO3ge4Wi",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "outputId": "934f514c-bb37-40a9-b91f-64bc6039becd"
      },
      "cell_type": "code",
      "source": [
        "# 계산 그래프 구성\n",
        "test_x, test_y = Variable(test_X), Variable(test_Y)\n",
        "# 출력이 0 혹은 1이 되게 함\n",
        "result = torch.max(model(test_x).data, 1)[1]\n",
        "# 모형의 정확도 측정\n",
        "accuracy = sum(test_y.cpu().data.numpy() == result.cpu().numpy()) / len(test_y.cpu().data.numpy())\n",
        "\n",
        "# 모형의 정확도 출력\n",
        "accuracy"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:27: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.988"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "metadata": {
        "id": "jYkZO3rmDVGA",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}